{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1890b16-e313-47b1-b27e-a9d5e2025153",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 10px; background-color: #64CCC5; margin: 10px; color: #000000; font-family: 'New Times Roman', serif; font-size: 60%; text-align: center; border-radius: 10px; overflow: hidden; font-weight: bold;\"> Question 1 : What is Bayes' theorem?</div>\n",
    "\n",
    "Bayes' theorem, named after Thomas Bayes, is a fundamental concept in probability theory and statistics. It provides a way to update probabilities based on new evidence or information. The theorem is formulated as follows:\n",
    "\n",
    "$$[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} ]$$\n",
    "where:\n",
    "- $(P(A|B))$ is the probability of event A occurring given that event B has occurred.\n",
    "- $(P(B|A))$ is the probability of event B occurring given that event A has occurred.\n",
    "- $(P(A))$ is the prior probability of event A.\n",
    "- $(P(B))$ is the prior probability of event B.\n",
    "\n",
    "Bayes' theorem is particularly useful in Bayesian statistics and is widely applied in various fields, including machine learning, medical diagnosis, and information retrieval. It allows for the incorporation of new evidence to update and refine the probability of a hypothesis or event."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47104ed8-d6f5-4144-8643-88f2752d1310",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 10px; background-color: #64CCC5; margin: 10px; color: #000000; font-family: 'New Times Roman', serif; font-size: 60%; text-align: center; border-radius: 10px; overflow: hidden; font-weight: bold;\"> Question 2 : What is the formula for Bayes' theorem?</div>\n",
    "\n",
    "Bayes' theorem is expressed mathematically as:\n",
    "\n",
    "$$[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} ]$$\n",
    "where:\n",
    "- $(P(A|B))$ is the probability of event A occurring given that event B has occurred.\n",
    "- $(P(B|A))$ is the probability of event B occurring given that event A has occurred.\n",
    "- $(P(A))$ is the prior probability of event A.\n",
    "- $(P(B))$ is the prior probability of event B.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41698fb1-627d-480f-ac2a-afba23b482dd",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 10px; background-color: #64CCC5; margin: 10px; color: #000000; font-family: 'New Times Roman', serif; font-size: 60%; text-align: center; border-radius: 10px; overflow: hidden; font-weight: bold;\"> Question 3 : How is Bayes' theorem used in practice? </div>\n",
    "\n",
    "Bayes' theorem is widely used in various fields and applications to update probabilities based on new evidence or information. Here's a general overview of how Bayes' theorem is applied in practice:\n",
    "\n",
    "1. **Defining Prior Probabilities (Prior Beliefs):** Before any new evidence is considered, there are initial beliefs or probabilities associated with different events. These are known as prior probabilities and are denoted by $(P(A))$ and $(P(B))$.\n",
    "\n",
    "2. **Incorporating New Evidence (Likelihood):** When new evidence or information becomes available, the likelihood of observing that evidence given certain hypotheses is assessed. This likelihood is represented by $(P(B|A))$, where A is the hypothesis and B is the evidence.\n",
    "\n",
    "3. **Calculating Joint Probabilities:** The joint probability of both the hypothesis and the evidence is computed by multiplying the prior probability of the hypothesis by the likelihood of the evidence: $(P(B|A)) \\cdot P(A))$.\n",
    "\n",
    "4. **Calculating the Normalization Factor (Marginal Likelihood):** The marginal likelihood or evidence, $(P(B))$, is calculated by considering all possible ways in which the evidence could occur, taking into account all possible hypotheses. It is the sum of the joint probabilities for all hypotheses: $(\\sum_{i} P(B|A_i) \\cdot P(A_i))$.\n",
    "\n",
    "5. **Updating Probabilities (Posterior Probability):** Bayes' theorem is then used to calculate the posterior probability, \\(P(A|B)\\), which represents the updated probability of the hypothesis given the new evidence. The formula is: \n",
    "\n",
    "   $[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} ]$\n",
    "   \n",
    "6. **Iterative Process:** This process can be repeated iteratively as new evidence becomes available, updating the probabilities and refining the beliefs over time.\n",
    "\n",
    "Applications of Bayes' theorem include:\n",
    "- **Medical Diagnosis:** Updating the probability of a disease given new test results.\n",
    "- **Spam Filtering:** Updating the probability of an email being spam based on observed features.\n",
    "- **Machine Learning:** Bayesian methods are used in machine learning for parameter estimation and model updating.\n",
    "- **Finance:** Assessing the probability of different financial outcomes based on market information.\n",
    "\n",
    "Bayes' theorem provides a principled way to incorporate new information into existing knowledge and is particularly useful in situations where uncertainty needs to be quantified and updated as evidence accumulates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c5176f-bb1b-44f7-bc3f-c60ef55b08be",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 10px; background-color: #64CCC5; margin: 10px; color: #000000; font-family: 'New Times Roman', serif; font-size: 60%; text-align: center; border-radius: 10px; overflow: hidden; font-weight: bold;\"> Question 4: What is the relationship between Bayes' theorem and conditional probability? </div>\n",
    "\n",
    "Bayes' theorem is closely related to conditional probability, and it can be derived from the definition of conditional probability. Let's explore this relationship:\n",
    "\n",
    "**Conditional Probability:**\n",
    "Conditional probability is the probability of an event occurring given that another event has already occurred. It is denoted as \\( P(A|B) \\) and is calculated using the formula:\n",
    "\n",
    "$[ P(A|B) = \\frac{P(A \\cap B)}{P(B)} ]$\n",
    "\n",
    "where:\n",
    "- $( P(A|B) )$ is the conditional probability of event A given that event B has occurred.\n",
    "- $( P(A \\cap B) )$ is the probability of both events A and B occurring.\n",
    "- $( P(B) )$ is the probability of event B occurring.\n",
    "\n",
    "**Bayes' Theorem:**\n",
    "Bayes' theorem is a way of expressing conditional probability in terms of other conditional probabilities and prior probabilities. It is formulated as:\n",
    "\n",
    "$[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} ]$\n",
    "\n",
    "where:\n",
    "- $( P(A|B) )$ is the conditional probability of event A given that event B has occurred.\n",
    "- $( P(B|A) )$ is the conditional probability of event B given that event A has occurred.\n",
    "- $( P(A) )$ is the prior probability of event A.\n",
    "- $( P(B) )$ is the prior probability of event B.\n",
    "\n",
    "**Relationship:**\n",
    "Bayes' theorem provides a way to express conditional probability in terms of prior probabilities and the likelihood of the evidence. By rearranging terms in Bayes' theorem, you can derive the formula for conditional probability:\n",
    "\n",
    "$[ P(A|B) = \\frac{P(B|A) \\cdot P(A)}{P(B)} ]$\n",
    "\n",
    "This relationship highlights how Bayes' theorem extends and connects with the concept of conditional probability. Bayes' theorem is a powerful tool for updating probabilities based on new evidence, making it particularly useful in situations where you want to refine your beliefs as more information becomes available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2b7e85-bc1a-40bd-a6a2-dd4464bc2d1d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 10px; background-color: #64CCC5; margin: 10px; color: #000000; font-family: 'New Times Roman', serif; font-size: 60%; text-align: center; border-radius: 10px; overflow: hidden; font-weight: bold;\"> Question 5 : How do you choose which type of Naive Bayes classifier to use for any given problem? </div>\n",
    "\n",
    "Choosing the right type of Naive Bayes classifier depends on the nature of your data and the underlying assumptions you can make about the independence of features. The three main types of Naive Bayes classifiers are:\n",
    "\n",
    "1. **Gaussian Naive Bayes:**\n",
    "   - **Assumption:** Assumes that the continuous features follow a Gaussian (normal) distribution.\n",
    "   - **Use Case:** Suitable for datasets where the features are continuous and approximately normally distributed.\n",
    "\n",
    "2. **Multinomial Naive Bayes:**\n",
    "   - **Assumption:** Appropriate for discrete data, such as word counts in text classification problems.\n",
    "   - **Use Case:** Commonly used in text classification tasks where features represent the frequency of words in documents.\n",
    "\n",
    "3. **Bernoulli Naive Bayes:**\n",
    "   - **Assumption:** Assumes that features are binary (i.e., present or absent).\n",
    "   - **Use Case:** Suitable for binary data, such as document classification where the presence or absence of certain words is considered.\n",
    "\n",
    "**Guidelines for Choosing:**\n",
    "\n",
    "1. **Nature of Features:**\n",
    "   - **Continuous Features:** If your features are continuous and approximately normally distributed, consider Gaussian Naive Bayes.\n",
    "   - **Discrete Features:** If your features are discrete, such as word counts or presence/absence indicators, consider Multinomial or Bernoulli Naive Bayes.\n",
    "\n",
    "2. **Dataset Size:**\n",
    "   - **Small Datasets:** In cases of small datasets, Naive Bayes classifiers, in general, can perform well. However, the choice between Gaussian, Multinomial, or Bernoulli depends on the nature of the features.\n",
    "\n",
    "3. **Independence Assumption:**\n",
    "   - **Features are Independent:** Naive Bayes classifiers assume independence between features. If this assumption is violated, the classifier might not perform well. Evaluate whether the independence assumption is reasonable for your data.\n",
    "\n",
    "4. **Text Classification:**\n",
    "   - **Word Frequency Data:** For text classification tasks where features represent word frequencies, Multinomial Naive Bayes is commonly used.\n",
    "   - **Presence/Absence of Words:** If you're dealing with binary data indicating the presence or absence of words (e.g., in spam filtering), Bernoulli Naive Bayes may be appropriate.\n",
    "\n",
    "5. **Experimentation:**\n",
    "   - **Try Different Types:** It's often beneficial to try different types of Naive Bayes classifiers on your dataset and compare their performance through cross-validation or other evaluation methods.\n",
    "\n",
    "Remember that the choice between these classifiers is not always strict, and experimentation is key to finding the most suitable model for your specific problem. Additionally, preprocessing steps, such as feature scaling or transformation, can also influence the performance of Naive Bayes classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cf7d2f-8775-4b47-87cf-3e078d3204af",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 10px; background-color: #64CCC5; margin: 10px; color: #000000; font-family: 'New Times Roman', serif; font-size: 60%; text-align: center; border-radius: 10px; overflow: hidden; font-weight: bold;\"> Question 6 : Assignment:</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5dddb49-4609-4ae3-be44-1952952b58c3",
   "metadata": {},
   "source": [
    "**You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of each feature value for each class:**\n",
    "```python\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "    A   3   3    4    4    3    3    3\n",
    "    B   2   2    1    2    2    2    3\n",
    "```\n",
    "    \n",
    "**Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance to belong to?**\n",
    "\n",
    "To use Naive Bayes for classification, you need to calculate the likelihood and the prior probabilities for each class. The class with the highest posterior probability given the new instance's features is the predicted class.\n",
    "\n",
    "Let's denote:\n",
    "- $( P(A) )$ and $( P(B) )$ as the prior probabilities of classes A and B, respectively. Since the prior probabilities are assumed to be equal, $( P(A) = P(B) = 0.5 )$.\n",
    "- $( P(X1=3 | A) )$ and $( P(X1=3 | B) )$ as the likelihoods of $( X1=3 )$ given classes A and B, respectively.\n",
    "- $( P(X2=4 | A) )$ and $( P(X2=4 | B) )$ as the likelihoods of $( X2=4 )$ given classes A and B, respectively.\n",
    "\n",
    "The likelihoods can be calculated from the provided table as follows:\n",
    "\n",
    "$[ P(X1=3 | A) = \\frac{4}{10} = 0.4 ]$\n",
    "$[ P(X1=3 | B) = \\frac{1}{9} ]$\n",
    "\n",
    "$[ P(X2=4 | A) = \\frac{3}{10} = 0.3 ]$\n",
    "$[ P(X2=4 | B) = \\frac{3}{9} ]$\n",
    "\n",
    "Now, the posterior probabilities for each class given the new instance's features are calculated using Bayes' theorem:\n",
    "\n",
    "$[ P(A | X1=3, X2=4) \\propto P(X1=3 | A) \\times P(X2=4 | A) \\times P(A) ]$\n",
    "$[ P(B | X1=3, X2=4) \\propto P(X1=3 | B) \\times P(X2=4 | B) \\times P(B) ]$\n",
    "\n",
    "Since we only need the relative probabilities, we can compare the products without normalizing:\n",
    "\n",
    "$[ P(A | X1=3, X2=4) \\propto 0.4 \\times 0.3 \\times 0.5 ]$\n",
    "$[ P(B | X1=3, X2=4) \\propto 0.0222 ]$\n",
    "\n",
    "Comparing the values, $( P(A | X1=3, X2=4) )$ is higher, so Naive Bayes would predict that the new instance belongs to class A."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6df23ba-af27-4bff-84e5-3034f5f4e092",
   "metadata": {
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 15px; background-color: #D2E0FB; margin: 15px; color: #000000; font-family: 'New Times Roman', serif; font-size: 110%; text-align: center; border-radius: 10px; overflow: hidden; font-weight: bold;\"> Complete</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
